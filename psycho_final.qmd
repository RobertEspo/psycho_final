---
title: "Predicting Sentence Modality in L1 and L2 Spanish: An Eye-tracking Study"
shorttitle: "Predicting Sentence Modality"
author:
  - name: Robert Esposito
    corresponding: true
    email: rme70@rutgers.edu
    affiliations:
      name: "Rutgers University"
      department: Department of Spanish and Portuguese
      address: 15 Seminary Pl.
      city: New Brunswick
      region: NJ
      country: USA
      postal-code: 08901
author-note:
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    # Example: This study was registered at X (Identifier Y).
    study-registration: ~
    # Acknowledge and cite data/materials to be shared.
    data-sharing: ~
    # Example: This article is based on data published in [Reference].
    # Example: This article is based on the dissertation completed by [citation].  
    related-report: ~
    # Example: [Author name] has been a paid consultant for Corporation X, which funded this study.
    conflict-of-interest: The authors have no conflicts of interest to disclose.
    # Example: This study was supported by Grant [Grant Number] from [Funding Source].
    financial-support: ~
    # Example: The authors are grateful to [Person] for [Reason].
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
number-sections: false
abstract: "Accurately parsing intonation is crucial for identifying sentence modality (i.e., declarative versus interrogative utterances) in Spanish. For example, *Mariano habla del tiempo* may variably be a statement ('Mariano talks about the weather') or a neutral information-seeking yes-no question ('Does Mariano talk about the weather?') depending on the intonation. Traditional analysis of Spanish intonation points to solely the final pitch movement as determining sentence modality [@tomas1944manual], but a recent gating experiment has demonstrated that L1 Spanish speakers can identify sentence modality by the first word [@face2007role]. Humans are believed to integrate linguistic information incrementally to make predictions about future content [@van2012prediction], and it follows that Spanish speakers would use early intonational cues to predict sentence modality instead of waiting for the final pitch movement, but there has yet to have been on-line measures to determine if sentence modality is predicted during real-time processing based on early intonational cues. This study uses eye-tracking to investigate L1 Spanish monolinguals' and L1 English L2 Spanish late learners' sensitivity to early intonational information for identifying sentence modality. Participants completed a two-alternative forced choice task in which they identified if an orally-delivered utterance was a question or not. Results of this study provide insight into understanding if either or both populations are sensitive to non-vital intonational information to predict sentence type. The findings of this study shed light on the incremental processing of intonational information as real-time sentence comprehension unfolds and provides information about which cues are recruited to make predictions."
keywords: [psycholinguistics, intonation, prediction, eye-tracking]
floatsintext: true
bibliography: "./lit/psycho_final.bib"
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    documentmode: man
---

```{r}
#| include: false
# load libs
library(here)
```

When listening to speech, humans are exposed to an acoustic signal that is seldom encoded in writing: fundamental frequency (F0). F0, modulated by how fast the vocal folds vibrate, is interpreted in human language as discrete pitch targets (high or low) and organized at the utterance-level to provide syntactic, pragmatic, and paralinguistic information [@ladd2008intonational]. Both native speakers (L1) and second language (L2) learners must accurately produce and perceive intonation to prevent communicative breakdowns. For example, distinguishing a sarcastic exclamation and a genuinely complimentary one in English (e.g., 'How smart she is!') requires correct parsing of intonation, as the utterance is identical at both the lexical (word) and syntactic (word-order) levels [@zhou2019detecting]. 

Even more quotidian, Spanish declaratives and yes-no questions are similarly distinguished only at the level of intonation: *Mariano habla del tiempo* ('Mariano talks about the weather') may variably be a statement or an information-seeking (i.e., neutral) yes-no question depending solely on intonation. Traditionally, only the final F0 movement of the utterance is analyzed as providing the disambiguating cue to determine if such an utterance is a declarative or interrogative. However, as early as @tomas1944manual, yes-no questions have been identified as having higher initial F0 than declaratives [@quilis1993filologia; @verdugo2005aproximacion], as well as carrying pitch accents on only the first and last words of the utterance [@prieto2004search]. @face2007role determined in an off-line gating experiment that L1 Spanish speakers can distinguish between these two sentence types as early as the first word, which encompasses the first F0 peak. While the final F0 movement strongly influenced participants' judgement, it appears that L1 Spanish speakers can use early intonational cues to determine sentence modality (i.e., whether an utterance is a declarative or interrogative) before the final movement is reached.

Although early intonation cues are available to L1 and L2 Spanish speakers to predict sentence modality [@face2007role; @face2005f0], there has been no investigation to determine if the cues are recruited as sentence comprehension unfolds to make predictions about sentence modality. Theoretical models of brain function suggest that the brain makes continuous predictions about future events based on Bayesian inferences [@bar2007proactive; @lee2003hierarchical; @van2012prediction; @altmann1999incremental; @gruter2021prediction]. It would be expected, then, that L1 Spanish and "proficient" (that is, native-like) L2 Spanish speakers would recruit intonational information as sentence processing unfolds to predict sentence modality.

The present study aims to determine if L1 and L2 Spanish speakers use early intonational cues identified by @face2007role and others to predict sentence modality using eye-tracking while participants complete a two-alternative forced choice (2AFC) task. The results will shed light on the weighting of early intonational cues compared to the final F0 movement in their usefulness to predicting sentence modality during real-time processing [@roettger2019evidential].

# Literature Review

## Early Cues to Sentence Modality in Spanish

Broadly speaking, intonation can be used to signal speech act marking, information status, belief status, and politeness, among many other communicative functions [@prieto2015intonational; @best2019diversity; @arvaniti2020autosegmental; @cruttenden1997intonation; @cutler1997prosody; @dahan2015prosody; @gussenhoven2004phonology; @ladd2008intonational]. Relevant to this study, intonation may also encode sentence modality: @hirst1998survey found that approximately 70% of a sample of nearly 250 languages used the final pitch movement to signal interrogativity. Spanish is an example of such a language, in which an utterance e.g., *Mariano habla del tiempo* ('Mariano talks about the weather') may variably be a statement or question, differentiated only by intonation. Importantly, @hirst1998survey categorized languages using only the final F0 movement, and this has been the traditional analysis for Spanish as well [@tomas1974manual; @hualde2008intonation]. 

Although the final F0 movement is seemingly the most salient in Spanish for determining sentence modality, it serving as the only cue in Spanish has been unequivocally rejected by @face2005f0['s] off-line gating experiment after previous investigations into earlier cues [@prieto2004search; @quilis1993filologia; @verdugo2005aproximacion]. He found that L1 Spanish speakers can accurately determine sentence modality by the scaling (i.e., height) of the first F0 peak and the presence or absence of a medial pitch accent. The availability of early cues to sentence modality is cohesive with what has been found for other lanugages lke English [@patience2018initial] and Dutch [@van2002temporal]. Speakers clearly have the early intonational cues available to them, but it remains uninvestigated if they recruit those early cues to predict sentence modality.

## Using Intonation to Predict

Humans constantly make predictions [@bar2007proactive; @lee2003hierarchical], and it follows that we also anticipate linguistic information [@van2012prediction], which has been demonstrated across linguistic domains [@altmann1999incremental]. Prosody and intonation have traditionally received little attention [@cutler1997prosody], but the extant research has demonstrated that listeners integrate intonational information as sentence processing unfolds to make predictions [@grodner2010some; @kamide2003time; @crocker2010computational; @levy2008expectation]. It seems unlikely, then, that Spanish speakers should wait until the very end of an utterance to determine sentence modality when they have other, earlier cues available to make accurate predictions [@face2007role].

Although cues may be available, it is not given that a monolingual listener will integrate the cue in real-time processing to make predictions; that is, not all cues are weighted equally [@kruschke2006locally]. @roettger2019evidential attempts to address this issue by introducing a computational model that proposes that the predictive value of an intonational cue is dependent on the prior reliability of the cue-to-function mapping and the likelihood of the mapping given the listener's most recent experiences. In a series of mouse-tracking studies, @roettger2021positional found that L1 German speakers do not use the presence of absence of a prenuclear pitch accent to predict the discourse status of an upcoming referent, but some L1 American English speakers, who have the same cue with the same predictive power available, do. This research puts doubt on the claim that L1 Spanish speakers recruit early intonational cues, as opposed to waiting for the final F0 movement.

## Prediction in a Second Language

There are few current L2 learning models that provide a framework for learning intonation. One available model is the L2 Intonation Learning theory [LILt; @mennen2015beyond], which predicts L2 learner outcomes by comparing the intonational systems of the two languages on four dimensions, predicated on L1-L2 transfer: (1) the inventory and distribution of categorical phonological elements; (2) the phonetic implementation of those elements; (3) the functionality of the elements; and (4) the frequency of use of each element. Unfortunately, there is only one cue that would traditionally be considered categorical in Spanish for sentence modality, and thus relevant to the model, that being the boundary tone [@prieto2010transcription]. Canonical yes-no questions in English are typically thought of as cued by a high boundary tone, but this does not actually seem to be the case: @geluykens1988myth found that it is more frequent to find low boundary tones with canonical yes-no questions in English. As such, the LILt model would actually predict some difficulty in acquiring a high boundary tone for Spanish neutral information-seeking yes-no questions by L1 English L2 Spanish learners.

It is unclear what predictions LILt makes for L1 English L2 Spanish late learners acquiring the early intonational cues to sentence modality in Spanish. English canonical yes-no questions are signaled primarily by syntactic (word-order) and lexical (e.g., do-support) elements, so intonational cues do not carry a high functional load. With regards to the first pitch peak, Spanish distinguishes between declaratives and interrogatives with pitch scaling, where a higher peak is associated with interrogativity. In English, pitch scaling is associated with emphasis [@chen2003reaction; @ladd1997perception]. L1 English speakers can use the first pitch accent type to disambiguate sentence type: yes-no questions typically have L\*+H as the first pitch accent, whereas declaratives are associated with H\* [@patience2018initial]. Although L1 English speakers may be tuned into the first pitch peak in Spanish, they may associate height differences as signalling emphasis, not sentence type. As for the presence or absence of a medial pitch accent, there is no extant research on such a phenomenon in English.

It is clear that L2 learners *can* predict in a qualitatively similar manner to L1 speakers [@gruter2021prediction], although typically with a delay, but it is unclear what determines their ability to do so. If @roettger2019evidential['s] computational model is to be adapted to an L2 context, we may wonder if L2 speakers with more opportunities to hear and utilize the cue-to-function mapping will show (faster) anticipatory behavior? The LILt model fails to provide predictions about learner outcomes based on individual differences, such as proficiency or exposure. @foltz2021using in an eye-tracking study found that L1 German L2 English intermediate-to-advanced learners [B2 or above using CEFR levels; @councilofeurope2001cefr] were able to predict a referent based on a contrastive pitch accent in their L1, but showed delayed processing for the same cue with the same predictive power in their L2. This is in contrast to @klassen2015second, who found that L1 Spanish L2 English intermediate-to-advanced learners did engage in predictive processing for a similar cue-to-function mapping. Although @foltz2021using contributes the differences to the amount of time that L2 learners had to predict in each task, the two participant groups differed in measures of self-reported proficiency and daily exposure to the L2: @foltz2021using['s] participants had overall lower self-reported proficiency scores than those of @klassen2015second; and although @foltz2021using did not report daily exposure scores, they were most likely much lower for the L1 German speakers living in Austria as opposed to @klassen2015second['s] L1 Spanish speakers living in the United States.

As it stands, L2 models of intonation do not yet provide enough predictive power on learner outcomes. Proficiency and exposure have been demonstrated to have strong effects on learner outcomes, and these measures should be teased apart to determine their individual contributions to phenomena such as that under investigation in the present study.

# The Current Study

Early intonational cues are available to predict sentence modality [@face2007role], but no previous research has investigated if L1 Spanish speakers recruit these early cues as sentence processing unfolds. @roettger2021positional['s] computational model predicts that not all possible cues are actually recruited. Furthermore, L1 English L2 Spanish speakers may have even greater difficulty integrating these cues since English primarily relies on lexical and syntactic cues, not intonational cues, to determine sentence modality. The current research investigates predictive capabilities of L1 Spain Spanish monolinguals and L1 UK English L2 Spain Spanish late learners for sentence modality. I have the following research questions regarding L1 Spain Spanish monolinguals to determine if early intonational cues are integrated during real-time processing to predict sentence modality:

1. Is the first F0 peak height used to predict sentence modality?

2. Is the presence or absence of a medial pitch accent used to predict sentence modality?

Based on @face2007role, it is expected that both cues will result in more target fixations.

The following research questions are aimed to investigate if L1 English L2 Spain Spanish speakers recruit the same early intonational cues to predict sentence. All questions are to be interpreted as applying to both the cues described in the first two research questions.

3. Do L1 English L2 Spanish speakers recruit either first F0 peak height or the presence/absence of a medial pitch accent to predict sentence modality?

4. Do prediction capabilities depend on proficiency?

5. Do prediction capabilities depend on daily exposure measures?

Due to lack of evidence, no hypothesis is proposed for RQ 3. If L2 learners *do* show anticipatory behavior, however, it is expected to occur with a delay [@corps2023two], but that delay will decrease with both greater proficiency and greater exposure.

# Method

## Participants

One hundred participants were recruited for the present study. Twenty-five participants (age: 18-35) were adult L1 Spanish speakers born, raised, and currently living in the Madrid, Spain area. These participants grew up as monolingual Spanish speakers and reported no proficiency in another language. They have spent less than three months in any non-Spanish speaking country.

The remaining 75 participants (age: 18-25) were L1 English L2 Spanish learners currently taking classes in Spanish at a university in the UK. Participants were born, raised, and currently living in the UK. They grew up monolingual English speakers, having begun the endeavor of acquiring Spanish at a mean age of 12 years old (SD = 4).

All participants had normal or corrected-to-normal vision. Participants received $15 for completing all tasks of the experiment.

## Materials

L2 Spanish participants completed a measure of Spanish proficiency, the LexTALE-ESP [@izura2014lextale] and a self-report language history background. The LexTALE-ESP is a measure of vocabulary size in Spanish that has been seen to correlate with other measures of proficiency. Participants were seen to have a range of Spanish proficiencies, from beginner to high-intermediate.

The language history background, completed by L1 Spanish participants in Spanish and L1 English participants in English online, collected information about participants' age of acquisition, cumulative language use, and current language use. Lower-proficiency participants had similar current language use scores, but higher-proficiency participants represented a range of current language use scores. These differences were attributed to extracurricular volunteer activities completed in the L2 Spanish.

Using the visual-world eye-tracking paradigm, participants were tested to determine if they were able to accurately determine whether a sentence was a declarative or interrogative before the final syllable. There were 60 experimental trials and 180 filler trials.

All experimental trial utterances consisted of an overt subject, a verb, and an object e.g., *Mariano habla del tiempo* ('Mariano talks about the weather'). The final word of the utterance always had penultimate stress so that the final pitch movement was not truncated with the nuclear pitch accent. Items were controlled for word frequency and duration.

The utterances were all produced by a 25-year-old female L1 Spanish monolingual speaker from Madrid. In total, she produced 30 pairs of identical utterances for a total of 60 utterances: half of the utterances were produced as declaratives, and the other half were produced as interrogatives. Acoustic analysis revealed that the first pitch peak of declarative utterances were always lower than the first pitch peak of the interrogative utterances. The declarative utterances were always produced with a medial pitch accent (e.g., on 'habla' in *Mariano habla del tiempo*), whereas this pitch accent was absent in interrogative utterances. As expected, declarative utterances ended with a low boundary tone, whereas interrogative utterances ended with a high boundary tone.

The visual display accompanying the auditory stimuli had two areas of interest depicting identical images of two people. One of the people had a speech bubble with either '.' or '?'. An example trial is depicted in @fig-example-trial.

```{r}
#| label: fig-example-trial
#| fig-cap: Example of one trial.

knitr::include_graphics(
  here("figs", "example_trial.bmp")
  )
```

## Procedure

Prior to the eye-tracking task, all participants consented to the experiment. They then completed the LexTALE-ESP and the language background questionnaire online on their personal computer. The LexTALE-ESP and the langauge background questionnaire took approximately 30 minutes to complete.

Participants were seated in front of an Eyelink Pro 1000 eye-tracking system (approximately 80 cm). Participants wore headphones to hear audio stimuli. Participants were told that they would hear a number of sentences and must determine if it was a 'statement', which corresponded to the image with a '.', or a 'yes-no question', which corresponded to the image with a '?'. The placement of the visual stimuli were counterbalanced. Participants were asked to press either the left or right shift key that corresponded with the image on the left or right side of the screen that matched the utterance's sentence type, and they could respond at any point during the utterance.

At trial start, participants were exposed to a fixation cross for 500ms, after which the two images appeared for 200ms. At 700ms into the trial, the audio stimuli began to play. Once the audio finished, participants could respond using the shift keys. Once they responded, a grey box appeared on the screen in one of the four corners. After they looked at the box for 500ms, the next trial began.

Participants completed four practice trials before the experiment to familiarize themselves with the images and task. Participants were then exposed to a total of 60 (20 experimental and 40 filler) trials. Experimental and filler trials appeared in randomized order. The eye-tracking task took approximately 15 minutes to complete.

# References

<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::
